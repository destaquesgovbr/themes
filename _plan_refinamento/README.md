# Fase 4: ValidaÃ§Ã£o e Refinamento da Ãrvore TemÃ¡tica

Este diretÃ³rio contÃ©m todos os scripts, dados e relatÃ³rios da **Fase 4** do projeto de refinamento da Ã¡rvore temÃ¡tica DestaquesGovBr.

## ğŸ“‹ VisÃ£o Geral

A Fase 4 consiste em 6 subfases para validar e refinar a Ã¡rvore temÃ¡tica enriquecida:

1. **Subfase 4.1:** ValidaÃ§Ã£o de ConsistÃªncia Estrutural
2. **Subfase 4.2:** ValidaÃ§Ã£o de Qualidade das DescriÃ§Ãµes
3. **Subfase 4.3:** PreparaÃ§Ã£o de Dataset de Teste
4. **Subfase 4.4:** Testes de ClassificaÃ§Ã£o Comparativos
5. **Subfase 4.5:** AnÃ¡lise de Resultados e Ajustes Iterativos
6. **Subfase 4.6:** DocumentaÃ§Ã£o Final e Entrega

**DocumentaÃ§Ã£o detalhada:** [FASE_4_DETALHAMENTO.md](./FASE_4_DETALHAMENTO.md)

## ğŸ“‚ Estrutura de DiretÃ³rios

```
_plan_refinamento/
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ FASE_4_DETALHAMENTO.md       # Plano detalhado completo
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ .python-version              # Python 3.13
â”‚
â”œâ”€â”€ scripts/                     # Scripts Python organizados
â”‚   â”œâ”€â”€ config.py               # ConfiguraÃ§Ãµes globais
â”‚   â”œâ”€â”€ utils/                  # UtilitÃ¡rios compartilhados
â”‚   â”œâ”€â”€ validacao/              # Subfase 4.1 e 4.2
â”‚   â”œâ”€â”€ dataset/                # Subfase 4.3
â”‚   â”œâ”€â”€ classificacao/          # Subfase 4.4
â”‚   â””â”€â”€ refinamento/            # Subfase 4.5
â”‚
â”œâ”€â”€ data/                        # Dados gerados
â”‚   â”œâ”€â”€ test_dataset.csv
â”‚   â”œâ”€â”€ embeddings_cache/       # Cache de embeddings
â”‚   â””â”€â”€ annotations/            # AnotaÃ§Ãµes manuais
â”‚
â”œâ”€â”€ reports/                     # RelatÃ³rios gerados
â”‚   â”œâ”€â”€ 01_estrutura_report.md
â”‚   â”œâ”€â”€ 02_qualidade_report.md
â”‚   â”œâ”€â”€ 03_classification_guide.md
â”‚   â”œâ”€â”€ 04_classification_results.md
â”‚   â”œâ”€â”€ 05_ajustes_realizados.md
â”‚   â””â”€â”€ 06_RELATORIO_VALIDACAO_FINAL.md
â”‚
â””â”€â”€ notebooks/                   # Jupyter notebooks
    â””â”€â”€ 06_classification_examples.ipynb
```

## ğŸš€ InÃ­cio RÃ¡pido

### 1. Ativar Ambiente Virtual

```bash
# Ativar virtual env do Poetry
source /Users/nitai/Library/Caches/pypoetry/virtualenvs/govbr-news-ai-_H0Lmpg7-py3.13/bin/activate

# Verificar Python 3.13
python --version
```

### 2. Instalar DependÃªncias

```bash
cd /Users/nitai/Dropbox/dev-mgi/destaquesgovbr/themes/_plan_refinamento
pip install -r requirements.txt
```

### 3. Executar Subfase 4.1 (ValidaÃ§Ã£o Estrutural)

```bash
python scripts/validacao/01_validate_structure.py
```

## ğŸ“Š Subfases Detalhadas

### Subfase 4.1: ValidaÃ§Ã£o Estrutural

**Scripts:**
- `scripts/validacao/01_validate_structure.py`

**Output:**
- `reports/01_estrutura_report.md`
- `reports/01_estrutura_stats.json`

**Como executar:**
```bash
python scripts/validacao/01_validate_structure.py
```

---

### Subfase 4.2: ValidaÃ§Ã£o de Qualidade

**Scripts:**
- `scripts/validacao/02_validate_quality.py`
- `scripts/validacao/02_analyze_similarity.py`
- `scripts/validacao/02_check_keywords.py`

**Output:**
- `reports/02_qualidade_report.md`
- `reports/02_problemas_qualidade.csv`
- `reports/02_similarity_matrix_L2.png`
- `reports/02_similarity_matrix_L3.png`

**Como executar:**
```bash
python scripts/validacao/02_validate_quality.py
python scripts/validacao/02_analyze_similarity.py
python scripts/validacao/02_check_keywords.py
```

---

### Subfase 4.3: Dataset de Teste

**Scripts:**
- `scripts/dataset/03_collect_news.py`
- `scripts/dataset/03_annotation_app.py`
- `scripts/dataset/03_validate_annotations.py`

**Output:**
- `data/test_dataset.csv`
- `reports/03_classification_guide.md`
- `reports/03_dataset_stats.md`

**Como executar:**
```bash
# Coletar notÃ­cias do Typesense
python scripts/dataset/03_collect_news.py

# Abrir interface de anotaÃ§Ã£o (Streamlit)
streamlit run scripts/dataset/03_annotation_app.py

# Validar anotaÃ§Ãµes
python scripts/dataset/03_validate_annotations.py
```

---

### Subfase 4.4: Testes de ClassificaÃ§Ã£o

**Scripts:**
- `scripts/classificacao/04_classifier.py`
- `scripts/classificacao/04_run_tests.py`
- `scripts/classificacao/04_calculate_metrics.py`
- `scripts/classificacao/04_analyze_errors.py`

**Output:**
- `reports/04_classification_results.md`
- `reports/04_metrics_summary.json`
- `reports/04_best_strategy_recommendation.md`
- `reports/04_confusion_matrices/`
- `reports/04_classification_errors.csv`

**Como executar:**
```bash
# Executar todos os testes (20 combinaÃ§Ãµes)
python scripts/classificacao/04_run_tests.py

# Calcular mÃ©tricas
python scripts/classificacao/04_calculate_metrics.py

# Analisar erros
python scripts/classificacao/04_analyze_errors.py
```

---

### Subfase 4.5: Refinamento

**Scripts:**
- `scripts/refinamento/05_analyze_confusions.py`
- `scripts/refinamento/05_suggest_fixes.py`
- `scripts/refinamento/05_apply_fixes.py`
- `scripts/refinamento/05_retest_themes.py`

**Output:**
- `reports/05_ajustes_realizados.md`
- `themes_tree_enriched_full.yaml` (versÃ£o 3.2+)
- `reports/05_improvements.md`
- `reports/05_iteration_log.md`

**Como executar:**
```bash
# Analisar confusÃµes
python scripts/refinamento/05_analyze_confusions.py

# Sugerir correÃ§Ãµes
python scripts/refinamento/05_suggest_fixes.py

# Aplicar correÃ§Ãµes aprovadas
python scripts/refinamento/05_apply_fixes.py

# Re-testar temas modificados
python scripts/refinamento/05_retest_themes.py
```

---

### Subfase 4.6: DocumentaÃ§Ã£o Final

**Output:**
- `reports/06_RELATORIO_VALIDACAO_FINAL.md`
- `reports/06_GUIA_USO_ARVORE_TEMATICA.md`
- `notebooks/06_classification_examples.ipynb`
- `reports/06_performance_benchmark.md`

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz deste diretÃ³rio:

```env
# Caminhos
THEMES_FILE=../themes_tree_enriched_full.yaml
TYPESENSE_HOST=localhost
TYPESENSE_PORT=8108
TYPESENSE_API_KEY=sua_chave_aqui

# Modelo de Embeddings
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2
EMBEDDING_CACHE_DIR=data/embeddings_cache

# Thresholds
CONFIDENCE_THRESHOLD_L1=0.4
CONFIDENCE_THRESHOLD_L2=0.5
CONFIDENCE_THRESHOLD_L3=0.6

# Dataset
TEST_DATASET_SIZE=500
ANNOTATION_BATCH_SIZE=50
```

### Config.py

O arquivo `scripts/config.py` carrega todas as configuraÃ§Ãµes automaticamente.

## ğŸ“ˆ CritÃ©rios de Sucesso

### Qualidade TÃ©cnica
- âœ… 0 erros estruturais no YAML
- âœ… 100% dos nÃ³s com campos obrigatÃ³rios
- âœ… < 5% de descriÃ§Ãµes com problemas ortogrÃ¡ficos

### Qualidade SemÃ¢ntica
- âœ… < 10% de pares de irmÃ£os com similaridade > 0.85
- âœ… Keywords relevantes e especÃ­ficas
- âœ… DescriÃ§Ãµes com comprimento adequado

### Performance de ClassificaÃ§Ã£o
- âœ… AcurÃ¡cia L1 â‰¥ 85% (top-1)
- âœ… AcurÃ¡cia L2 â‰¥ 70% (top-1)
- âœ… AcurÃ¡cia L3 â‰¥ 60% (top-1)
- âœ… AcurÃ¡cia hierÃ¡rquica completa â‰¥ 55%

## ğŸ› Troubleshooting

### Erro: Modelo de embeddings nÃ£o encontrado

```bash
# Baixar modelo manualmente
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
```

### Erro: MemÃ³ria insuficiente

- Reduzir batch size de embeddings em `config.py`
- Usar modelo menor: `distiluse-base-multilingual-cased-v2`

### Erro: Typesense connection refused

- Verificar se Typesense estÃ¡ rodando: `docker ps | grep typesense`
- Verificar credenciais em `.env`

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Consultar [FASE_4_DETALHAMENTO.md](./FASE_4_DETALHAMENTO.md)
2. Verificar logs em `reports/`
3. Abrir issue no repositÃ³rio

## ğŸ“ LicenÃ§a

Projeto interno - DestaquesGovBr
